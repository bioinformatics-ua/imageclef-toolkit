{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageCLEF 2018 concept detector - logistic regression\n",
    "\n",
    "This notebook performs multi-label classification of biomedical concepts with logistic regression. The feature sets, built separately, are loaded from HDF5 files.\n",
    "\n",
    "You may read more about this approach in our working notes:\n",
    "\n",
    "> Eduardo Pinho and Carlos Costa. _Feature Learning with Adversarial Networks for Concept Detection in Medical Images: UA.PT Bioinformatics at ImageCLEF 2018_, CLEF working notes, CEUR, 2018.\n",
    "\n",
    "#### Instructions of use\n",
    "\n",
    "1. Run preamble cells below.\n",
    "\n",
    "2. Pick an existing representation kind, run the respective data set loading and training bundle harness creation cells.\n",
    "\n",
    "3. Choose the number of epochs to train, run respective cell.\n",
    "\n",
    "4. View the results with the following cell, go to step 3 at will to keep on training.\n",
    "\n",
    "5. When done, print the test set predictions in the following cell.\n",
    "\n",
    "#### HDF5 data format\n",
    "\n",
    "All feature files must contain these two datasets:\n",
    "\n",
    "- `/data`: (N, D), 32-bit float containing the feature vectors\n",
    "- `/id`: (N,), variably-lengthed UTF-8 string containing the image ID (the file name without the extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from util import *\n",
    "from lin import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read concept list (in frequency order)\n",
    "\n",
    "The following cell creates a list of concepts and their counts in descending order of frequency. This allows us to focus on classifying more balanced labels (they are generally very sparse). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./vocabulary.csv\", encoding=\"utf-8\") as file:\n",
    "    CONCEPT_LIST = []\n",
    "    CONCEPT_COUNT = []\n",
    "    for x in file:\n",
    "        parts = x.strip().split('\\t')\n",
    "        CONCEPT_LIST.append(parts[0])\n",
    "        CONCEPT_COUNT.append(int(parts[1]))\n",
    "        \n",
    "    CONCEPT_COUNT = np.array(CONCEPT_COUNT)\n",
    "CONCEPT_MAP = {cname: v for (v, cname) in enumerate(CONCEPT_LIST)}\n",
    "print(\"Number of concepts:\", len(CONCEPT_MAP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read ground truth\n",
    "\n",
    "Please **add the concept list file** to this directory, or modify the file path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all = build_labels('./ConceptDetectionTraining2018-Concepts.csv', CONCEPT_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label statistics\n",
    "\n",
    "The constants below are specific to the ImageCLEF 2018 caption task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 223859\n",
    "N_TESTING_SAMPLES = 9938\n",
    "N_LABELED_SAMPLES = N_SAMPLES - len(labels_all)\n",
    "print(\"{} items in full data set without labels ({:.4}% of set)\".format(\n",
    "    N_LABELED_SAMPLES, N_LABELED_SAMPLES * 100.0 / N_SAMPLES))\n",
    "N_AVERAGE_LABELS = np.mean([len(c) for c in labels_all.values()])\n",
    "print(\"Each labeled item contains {} labels on average\".format(N_AVERAGE_LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make train-val split partition\n",
    "\n",
    "In order to obtain some feedback on the training process, the training set is split into two parts. In this code, 10% of the data set was separated for tuning the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_VALIDATION = N_SAMPLES // 10\n",
    "N_TRAINING_SAMPLES = N_SAMPLES - N_VALIDATION\n",
    "RANDOM_SEED = 63359405\n",
    "\n",
    "print(\"Using {} validation samples (out of {})\".format(N_VALIDATION, N_SAMPLES))\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "all_indices = list(range(N_SAMPLES))\n",
    "val_indices = random.sample(all_indices, k=N_VALIDATION)\n",
    "train_indices = np.delete(all_indices, val_indices)\n",
    "assert len(train_indices) + len(val_indices) == N_SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation with Logistic Regression\n",
    "\n",
    "The following constants may be adjusted to select which concepts to classify, starting from the most frequent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = 500       # just these most frequent features\n",
    "N_TRAIN_OFFSET = 0  # skip these most frequent features first\n",
    "\n",
    "# -------------- AUTOMATICALLY CALCULATED, DO NOT MODIFY --------------\n",
    "CONCEPTS_TO_TRAIN = CONCEPT_LIST[N_TRAIN_OFFSET:N_TRAIN_OFFSET + N_TRAIN]\n",
    "# calculate the probability of each concept (based on its frequency in the training set)\n",
    "CONCEPTS_PROB = CONCEPT_COUNT[N_TRAIN_OFFSET:N_TRAIN_OFFSET + N_TRAIN] / N_SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating point thresholds\n",
    "\n",
    "Choose a list of operating point thresholds to consider in the fine-tuning process. A threshold of 0.5 maximizes accuracy, but is not very useful in this context, since the concepts are very sparse and infrequent. On the other hand, excessively low thresholds will yield too many concepts, decreasing precision. By defining multiple thresholds, we are searching for the one that will maximize the $F_1$ score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.06, 0.0625, 0.07, 0.075, 0.08, 0.1, 0.125, 0.15, 0.175]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bags of Colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code uses features based on an implementation of bags of colors. Please see [this repository](https://github.com/Enet4/bag-of-colors-nb) for the implementation. It was only written after the 2018 challenge.\n",
    "\n",
    "The following cell loads the training set, splits it, and loads the testing set. Please make sure that you have both the train and testing feature files. If they have a different name, feel free to change them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boc_dset = Datasets.from_h5_files_partition(\n",
    "    './bocs-256-train.h5',\n",
    "    train_indices,\n",
    "    './bocs-256-test.h5',\n",
    "    labels_all,\n",
    "    CONCEPTS_TO_TRAIN,\n",
    "    N_TRAIN_OFFSET,\n",
    "    normalizer_fn=max_normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates a model for logistic regression and respective estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = build_model_fn(\n",
    "    n_classes=N_TRAIN,\n",
    "    x_shape=[boc_dset.train_x.shape[1]],\n",
    "    learning_rate=0.05,\n",
    "    thresholds=thresholds\n",
    ")\n",
    "boc_estimator = tf.estimator.Estimator(model_fn=model_fn, config=get_config('boc'))\n",
    "boc_bundle = TrainBundle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_eval_boc = build_train_and_eval_function(\n",
    "    boc_estimator, boc_bundle, boc_dset, thresholds, CONCEPTS_TO_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell performs the actual training, evaluation, and test predictions. It can be run multiple times. Consider trying a small number of epochs as the argument and running the cell multiple times to see the outcomes earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boc_f1, boc_test_predictions = train_and_eval_boc(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell shows the progression of $F_1$ scores with training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_eval(boc_bundle, thresholds, name=\"boc\")\n",
    "print(\"Best F1:\", boc_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the submission file can be built with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write predictions to file\n",
    "print_predictions(boc_test_predictions, boc_bundle.all_metrics, key=\"lin-boc-{}-o{}\".format(N_TRAIN, N_TRAIN_OFFSET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline replicates itself below for other kinds of visual features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Auto-Encoder\n",
    "\n",
    "Please see [imageclef-aae](https://github.com/bioinformatics-ua/imageclef-toolkit/tree/master/caption/imageclef-aae) to train an adversarial auto-encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aae_dset = Datasets.from_pair_files_partition(\n",
    "    './aae-features-train.h5',\n",
    "    './aae-list-train.txt',\n",
    "    train_indices,\n",
    "    './aae-features-test.h5',\n",
    "    './aae-list-test.txt',\n",
    "    labels_all,\n",
    "    CONCEPTS_TO_TRAIN,\n",
    "    offset=N_TRAIN_OFFSET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = build_model_fn(\n",
    "    n_classes=N_TRAIN,\n",
    "    x_shape=[aae_val_x.shape[1]],\n",
    "    learning_rate=0.05,\n",
    "    thresholds=thresholds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aae_estimator = tf.estimator.Estimator(model_fn=model_fn, config=get_config('aae'))\n",
    "aae_bundle = TrainBundle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_eval_aae = build_train_and_eval_function(\n",
    "    aae_estimator, aae_bundle, aae_dset, thresholds, CONCEPTS_TO_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aae_f1, aae_test_predictions = train_and_eval_aae(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_eval(aae_bundle, thresholds, name=\"aae\")\n",
    "print(\"Best F1:\", aae_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write predictions to file\n",
    "print_predictions(aae_test_predictions, aae_bundle.all_metrics, key=\"aae-{}-o{}\".format(N_TRAIN, N_TRAIN_OFFSET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flipped-Adversarial Auto-Encoder\n",
    "\n",
    "Please see [imageclef-aae](https://github.com/bioinformatics-ua/imageclef-toolkit/tree/master/caption/imageclef-aae) to train a flipped-adversarial auto-encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faae_dset = Datasets.from_h5_files_partition(\n",
    "    './faae-features-train.h5',\n",
    "    train_indices,\n",
    "    './aae-features-test.h5',\n",
    "    labels_all,\n",
    "    CONCEPTS_TO_TRAIN,\n",
    "    offset=N_TRAIN_OFFSET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = build_model_fn(\n",
    "    n_classes=N_TRAIN,\n",
    "    x_shape=[faae_dset.train_x.shape[1]],\n",
    "    learning_rate=0.05,\n",
    "    thresholds=thresholds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faae_estimator = tf.estimator.Estimator(model_fn=model_fn, config=get_config('faae'))\n",
    "faae_bundle = TrainBundle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_eval_faae = build_train_and_eval_function(\n",
    "    faae_estimator, faae_bundle, faae_dset, thresholds, CONCEPTS_TO_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faae_f1, faae_test_predictions = train_and_eval_faae(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_eval(aae_bundle, thresholds, name=\"faae\")\n",
    "print(\"Best F1:\", faae_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write predictions to file\n",
    "print_predictions(faae_test_predictions, faae_bundle.all_metrics, key=\"faae-{}-o{}\".format(N_TRAIN, N_TRAIN_OFFSET))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
